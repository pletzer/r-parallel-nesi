[scheduling] # Define the tasks and when they should run
  [[graph]]
    R1 = """ # R1 means run this graph once
      install => serial & 
                 shrd-nw10 & shrd-nw20 & shrd-nw50 &
                 dist-nw10 & dist-nw20 & dist-nw50 & dist-nw100 & dist-nw10-openmpi
      serial & 
      shrd-nw10  & shrd-nw20 & shrd-nw50 & 
      dist-nw10 & dist-nw20 & dist-nw50 & dist-nw100 & dist-nw10-openmpi => analyse
    """
[runtime] # Define what each task should run
  [[root]] # Default settings inherited by all tasks
    platform = mahuika-slurm # Run "cylc conf" to see platforms. 
    [[[directives]]] # Default SLURM options for the tasks below
       --account = nesi99999 # CHANGE
       --hint = nomultithread
       --partition = milan
       --nodes = 1
    [[[environment]]]
      TOP_DIR="/nesi/nobackup/pletzera/r-parallel-nesi/" # CHANGE
      NTASKS=10000
      BIN_DIR=$CYLC_WORKFLOW_SHARE_DIR/bin
  [[install]]
        script = """
# copy the R scripts to a directory that belongs to the workflow, this allows 
# one to continuously update the scripts without affecting a currently running 
# workflow
          mkdir -p $BIN_DIR
          cp $TOP_DIR/*/*.R $BIN_DIR
          echo "BIN_DIR = $BIN_DIR"
          echo "scripts in $BIN_DIR: $(ls $BIN_DIR)"
        """
        platform = localhost
  [[serial]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/serial.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 1
        --cpus-per-task = 1
  [[shrd-nw10]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/shared.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 1
        --cpus-per-task = 10
  [[shrd-nw20]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/shared.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 1
        --cpus-per-task = 20
  [[shrd-nw50]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/shared.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 1
        --cpus-per-task = 50
  [[dist-nw10]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/distributed.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 10
        --cpus-per-task = 1
  [[dist-nw20]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/distributed.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 20
        --cpus-per-task = 1
  [[dist-nw50]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/distributed.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 50
        --cpus-per-task = 1
  [[dist-nw100]]
    script = """
          module purge
          module load R
          srun Rscript $BIN_DIR/distributed.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 100
        --cpus-per-task = 1
  [[dist-nw10-openmpi]]
    script = """
          module purge
          module load R
          module load OpenMPI
          srun Rscript $BIN_DIR/distributed.R $NTASKS
      """
      [[[directives]]] # specific SLURM option for this task
        --ntasks = 10
        --cpus-per-task = 1
  [[analyse]]
    platform = localhost
    script = """
        sqlite3 $CYLC_WORKFLOW_RUN_DIR/log/db "select job_id, cycle, name, submit_num, time_run, time_run_exit from task_jobs;" > table.txt
        cat table.txt
        # create plot
        module load R
        Rscript $BIN_DIR/analyse.R $NTASKS
    """

